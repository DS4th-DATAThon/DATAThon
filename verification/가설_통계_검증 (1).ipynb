{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c566f0-b4f7-4414-bbf3-73e0fefae9f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. 고유한 값, 결측치가 많은 컬럼들을 삭제 후 모델링하면 성능 향상할 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "698d8be1-95ae-4762-8b37-bed52e151e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('~/Aiffel/DATAThon/playground-series-s4e11/train.csv')\n",
    "test = pd.read_csv('~/Aiffel/DATAThon/playground-series-s4e11/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3fb2e109-70ba-442a-96fd-2766d4b2a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Name', 'City', 'Profession', 'Sleep Duration', 'Age', 'Degree','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e5cf184f-9105-42bb-ab0f-ab7a4146b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 처리\n",
    "train.drop(columns=['CGPA'], inplace=True)\n",
    "train['Academic_Pressure_missing'] = train['Academic Pressure'].isnull().astype(int)\n",
    "train['Study_Satisfaction_missing'] = train['Study Satisfaction'].isnull().astype(int)\n",
    "imputer_ap = SimpleImputer(strategy='mean')\n",
    "imputer_ss = SimpleImputer(strategy='mean')\n",
    "train['Academic Pressure'] = imputer_ap.fit_transform(train[['Academic Pressure']])\n",
    "train['Study Satisfaction'] = imputer_ss.fit_transform(train[['Study Satisfaction']])\n",
    "train['Work_Pressure_missing'] = train['Work Pressure'].isnull().astype(int)\n",
    "train['Job_Satisfaction_missing'] = train['Job Satisfaction'].isnull().astype(int)\n",
    "imputer_wp = SimpleImputer(strategy='mean')\n",
    "imputer_js = SimpleImputer(strategy='mean')\n",
    "train['Work Pressure'] = imputer_wp.fit_transform(train[['Work Pressure']])\n",
    "train['Job Satisfaction'] = imputer_js.fit_transform(train[['Job Satisfaction']])\n",
    "train = train[train['Financial Stress'].notnull()].copy()\n",
    "\n",
    "valid_dietary = ['Moderate', 'Unhealthy', 'Healthy']\n",
    "train['Dietary Habits'] = train['Dietary Habits'].where(train['Dietary Habits'].isin(valid_dietary))\n",
    "train['Dietary Habits'] = train['Dietary Habits'].fillna(train['Dietary Habits'].mode()[0])\n",
    "\n",
    "binary_cols = ['Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
    "for col in binary_cols:\n",
    "    train[col] = train[col].map({'Yes': 1, 'No': 0})\n",
    "train['Gender'] = train['Gender'].map({'Male': 1, 'Female': 0})\n",
    "train['Working Professional or Student'] = train['Working Professional or Student'].map({'Working Professional': 1, 'Student': 0})\n",
    "\n",
    "# 수치형 변수 스케일링\n",
    "scale_cols = ['Work/Study Hours', 'Financial Stress']\n",
    "# scale_cols = ['Age', 'Sleep Duration', 'Work/Study Hours', 'Financial Stress']\n",
    "scaler = StandardScaler()\n",
    "train[scale_cols] = scaler.fit_transform(train[scale_cols])\n",
    "\n",
    "train = pd.get_dummies(train, columns=['Dietary Habits'], drop_first=True) # 다중공선성 방지를 위해 첫 번째 범주는 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1b653f6b-fb55-465a-9866-a3a8ab41d247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:40:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:40:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:40:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:40:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:40:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:40:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:40:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:40:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:40:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:40:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (10회): [0.913  0.9132 0.9135 0.9134 0.9134 0.9126 0.914  0.9118 0.9131 0.9118]\n",
      "Recall (10회):    [0.6815 0.6733 0.6793 0.6747 0.679  0.6728 0.6823 0.6711 0.6777 0.6731]\n",
      "\n",
      "평균 Accuracy: 0.9130\n",
      "평균 Recall:   0.6765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "accuracy_list = []\n",
    "recall_list = []\n",
    "\n",
    "# 10회 반복\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        train.drop(columns=['Depression']),\n",
    "        train['Depression'],\n",
    "        test_size=0.3,\n",
    "        stratify=train['Depression'],\n",
    "        random_state=i  # 반복마다 seed 변경\n",
    "    )\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    recall_list.append(rec)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Accuracy (10회):\", np.round(accuracy_list, 4))\n",
    "print(\"Recall (10회):   \", np.round(recall_list, 4))\n",
    "print(f\"\\n평균 Accuracy: {np.mean(accuracy_list):.4f}\")\n",
    "print(f\"평균 Recall:   {np.mean(recall_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e7ec1-b817-482d-aba5-253d38990eba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. 학생 / 직장인 데이터를 분리하여 모델링하면 성능 향상할 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b8cdb0d2-cbd9-4eb0-b84a-5c88a716dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('~/Aiffel/DATAThon/playground-series-s4e11/train.csv')\n",
    "test = pd.read_csv('~/Aiffel/DATAThon/playground-series-s4e11/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2942d901-2b03-44c5-80b2-e04119bb6f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/5rb3dt8x3mq707hsrnthhx2w0000gn/T/ipykernel_1363/966698980.py:95: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  work_train['Profession'].fillna('Missing', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train.drop(columns=['id'], inplace=True)\n",
    "train.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "# 이상치, 알 수 없는 값들 제거\n",
    "delete_values = [\n",
    "    'Indore', 'Pune', 'Moderate', 'Unhealthy', 'Sleep_Duration',\n",
    "    'Work_Study_Hours', 'No', '45', '49 hours', '55-66 hours', '40-45 hours', \n",
    "    '9-5 hours', '10-6 hours', '9-6 hours', '9-5', '45-48 hours', '35-36 hours'\n",
    "]\n",
    "\n",
    "train = train[~train['Sleep Duration'].isin(delete_values)].copy()\n",
    "\n",
    "def convert_sleep_to_hours(val):\n",
    "    try:\n",
    "        val = str(val).strip().lower()\n",
    "\n",
    "        # 특별 처리: 'than n hours' → 'less than n hours' 간주\n",
    "        if 'than' in val and 'less' not in val and 'more' not in val:\n",
    "            match = re.search(r'\\d+', val)\n",
    "            if match:\n",
    "                return float(match.group()) - 0.5\n",
    "\n",
    "        # Less than n hours → n - 0.5\n",
    "        if 'less than' in val:\n",
    "            match = re.search(r'\\d+', val)\n",
    "            if match:\n",
    "                return float(match.group()) - 0.5\n",
    "\n",
    "        # More than n hours → n + 0.5\n",
    "        elif 'more than' in val:\n",
    "            match = re.search(r'\\d+', val)\n",
    "            if match:\n",
    "                return float(match.group()) + 0.5\n",
    "\n",
    "        # 정확히 n hours → 숫자만 추출\n",
    "        elif re.match(r'^\\d+\\s*hours$', val):\n",
    "            return float(re.findall(r'\\d+', val)[0])\n",
    "\n",
    "        # n-m hours 또는 n–n → 평균값\n",
    "        elif re.search(r'\\d+\\s*[-–~]\\s*\\d+', val):\n",
    "            nums = [int(n) for n in re.findall(r'\\d+', val)]\n",
    "            if len(nums) == 2:\n",
    "                return sum(nums) / 2\n",
    "\n",
    "        # 숫자만 → 그대로\n",
    "        elif re.match(r'^\\d+(\\.\\d+)?$', val):\n",
    "            return float(val)\n",
    "\n",
    "        # 나머지는 이상값으로 간주\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "train['Sleep Duration'] = train['Sleep Duration'].apply(convert_sleep_to_hours)\n",
    "\n",
    "work_train = train[train['Working Professional or Student'] == 'Working Professional']\n",
    "stu_train = train[train['Working Professional or Student'] == 'Student']\n",
    "\n",
    "#직장인 테이블 결측치 제거\n",
    "work_cols_to_drop = ['Academic Pressure', 'Study Satisfaction', 'CGPA']\n",
    "work_train = work_train.drop(columns=work_cols_to_drop)\n",
    "\n",
    "#학생 테이블 결측치 제거\n",
    "stu_cols_to_drop = ['Work Pressure', 'Job Satisfaction', 'Profession']\n",
    "stu_train = stu_train.drop(columns=stu_cols_to_drop)\n",
    "\n",
    "# 1. CGPA 컬럼 제거\n",
    "stu_train.drop(columns=['CGPA'], inplace=True)\n",
    "\n",
    "# 2. Academic Pressure 결측 여부 파생 변수\n",
    "stu_train['Academic_Pressure_missing'] = stu_train['Academic Pressure'].isnull().astype(int)\n",
    "\n",
    "# 3. Study Satisfaction 결측 여부 파생 변수\n",
    "stu_train['Study_Satisfaction_missing'] = stu_train['Study Satisfaction'].isnull().astype(int)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  # 또는 'median', 'most_frequent'\n",
    "stu_train['Academic Pressure'] = imputer.fit_transform(stu_train[['Academic Pressure']])\n",
    "stu_train['Study Satisfaction'] = imputer.fit_transform(stu_train[['Study Satisfaction']])\n",
    "\n",
    "# 4. Work_Pressure_missing 결측 여부 파생 변수\n",
    "work_train['Work_Pressure_missing'] = work_train['Work Pressure'].isnull().astype(int)\n",
    "# 5. Job_Satisfaction_missing 결측 여부 파생 변수\n",
    "work_train['Job_Satisfaction_missing'] = work_train['Job Satisfaction'].isnull().astype(int)\n",
    "\n",
    "work_train['Work Pressure'] = imputer.fit_transform(work_train[['Work Pressure']])\n",
    "work_train['Job Satisfaction'] = imputer.fit_transform(work_train[['Job Satisfaction']])\n",
    "\n",
    "work_train = work_train[work_train['Financial Stress'].notnull()].copy()\n",
    "stu_train = stu_train[stu_train['Financial Stress'].notnull()].copy()\n",
    "\n",
    "work_train['Profession'].fillna('Missing', inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale_cols = ['Age', 'Sleep Duration', 'Work/Study Hours', 'Financial Stress']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "work_train[scale_cols] = scaler.fit_transform(work_train[scale_cols])\n",
    "stu_train[scale_cols] = scaler.fit_transform(stu_train[scale_cols])\n",
    "\n",
    "degree_group_map = {\n",
    "    # 의학/보건\n",
    "    'MD': 'Medical',\n",
    "    'MBBS': 'Medical',\n",
    "    'B.Pharm': 'Pharmacy',\n",
    "    'M.Pharm': 'Pharmacy',\n",
    "    'MPharm': 'Pharmacy',\n",
    "    'P.Pharm': 'Pharmacy',\n",
    "    'S.Pharm': 'Pharmacy',\n",
    "    'N.Pharm': 'Pharmacy',\n",
    "\n",
    "    # 공학/기술\n",
    "    'B.Tech': 'Engineering',\n",
    "    'M.Tech': 'Engineering',\n",
    "    'ME': 'Engineering',\n",
    "    'MTech': 'Engineering',\n",
    "    'M_Tech': 'Engineering',\n",
    "    'BE': 'Engineering',\n",
    "    'BCA': 'Engineering',\n",
    "    'MCA': 'Engineering',\n",
    "    'E.Tech': 'Engineering',\n",
    "    'S.Tech': 'Engineering',\n",
    "    'LLTech': 'Engineering',\n",
    "    'LLCom': 'Engineering',\n",
    "\n",
    "    # 인문/사회/비즈니스\n",
    "    'BBA': 'Business',\n",
    "    'MBA': 'Business',\n",
    "    'M. Business Analyst': 'Business',\n",
    "    'B.Com': 'Commerce',\n",
    "    'M.Com': 'Commerce',\n",
    "    'P.Com': 'Commerce',\n",
    "    'LLB': 'Law',\n",
    "    'LLM': 'Law',\n",
    "    'LLBA': 'Law',\n",
    "    'LL.Com': 'Law',\n",
    "    'LL B.Ed': 'Education',\n",
    "    'B.Ed': 'Education',\n",
    "    'M.Ed': 'Education',\n",
    "    'L.Ed': 'Education',\n",
    "    'K.Ed': 'Education',\n",
    "    'LLEd': 'Education',\n",
    "    'BEd': 'Education',\n",
    "\n",
    "    # 과학\n",
    "    'BSc': 'Science',\n",
    "    'MSc': 'Science',\n",
    "    'B.Sc': 'Science',\n",
    "\n",
    "    # 기타, 건축, 호텔경영 등\n",
    "    'BHM': 'Hospitality',\n",
    "    'MHM': 'Hospitality',\n",
    "    'B.Arch': 'Architecture',\n",
    "    'M.Arch': 'Architecture',\n",
    "    'BArch': 'Architecture',\n",
    "    'B.B.Arch': 'Architecture',\n",
    "\n",
    "    # 학위 및 학교 졸업\n",
    "    'PhD': 'PhD',\n",
    "    'Class 12': 'School',\n",
    "    'Class 11': 'School',\n",
    "}\n",
    "\n",
    "work_train['degree_group'] = work_train['Degree'].apply(lambda x: degree_group_map.get(x, 'Other'))\n",
    "stu_train['degree_group'] = stu_train['Degree'].apply(lambda x: degree_group_map.get(x, 'Other'))\n",
    "\n",
    "work_train=work_train.drop('Degree',axis=1)\n",
    "stu_train=stu_train.drop('Degree',axis=1)\n",
    "\n",
    "# 정상 값만 남기고 나머지는 NaN으로\n",
    "valid_dietary = ['Moderate', 'Unhealthy', 'Healthy']\n",
    "work_train['Dietary Habits'] = work_train['Dietary Habits'].where(work_train['Dietary Habits'].isin(valid_dietary))\n",
    "stu_train['Dietary Habits'] = stu_train['Dietary Habits'].where(stu_train['Dietary Habits'].isin(valid_dietary))\n",
    "\n",
    "# 결측값은 최빈값으로 ㅁ\n",
    "work_train['Dietary Habits'] = work_train['Dietary Habits'].fillna(work_train['Dietary Habits'].mode()[0])\n",
    "stu_train['Dietary Habits'] = stu_train['Dietary Habits'].fillna(stu_train['Dietary Habits'].mode()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "45278446-f0a3-463e-a66d-5483321cfc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Gender, Working Status - Binary\n",
    "list = [work_train, stu_train]\n",
    "\n",
    "for train in list :\n",
    "    train['Gender'] = train['Gender'].map({'Male': 1, 'Female': 0})\n",
    "    train['Working Professional or Student'] = train['Working Professional or Student'].map({'Working Professional': 1, 'Student': 0})\n",
    "\n",
    "# Degree, Dietary Habits - One-hot encoding\n",
    "work_train = pd.get_dummies(work_train, columns=['degree_group', 'Dietary Habits'], drop_first=True)\n",
    "stu_train = pd.get_dummies(stu_train, columns=['degree_group', 'Dietary Habits'], drop_first=True)\n",
    "\n",
    "# Profession, City - Target encoding (또는 frequency encoding)\n",
    "# 예: Target Mean Encoding (Depression 컬럼 사용)\n",
    "for col in ['Profession', 'City']:\n",
    "    target_mean = work_train.groupby(col)['Depression'].mean()\n",
    "    work_train[col + '_target'] = work_train[col].map(target_mean)\n",
    "\n",
    "# 이후 필요시 원본 컬럼 제거\n",
    "work_train.drop(columns=['Profession', 'City'], inplace=True)\n",
    "\n",
    "## 2 ## \n",
    "for col in ['City']:\n",
    "    target_mean = stu_train.groupby(col)['Depression'].mean()\n",
    "    stu_train[col + '_target'] = stu_train[col].map(target_mean)\n",
    "\n",
    "# 이후 필요시 원본 컬럼 제거\n",
    "stu_train.drop(columns=[ 'City'], inplace=True)\n",
    "\n",
    "binary_cols = ['Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
    "for col in binary_cols:\n",
    "    work_train[col] = work_train[col].map({'Yes': 1, 'No': 0})\n",
    "    stu_train[col] = stu_train[col].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "567dcc27-c5b0-4c47-af9f-79f83977f221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:46:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 [직장인] Accuracy (10회): [0.9605 0.9623 0.9618 0.9611 0.9605 0.9607 0.9613 0.9635 0.9615 0.9621]\n",
      "📊 [직장인] Recall    (10회): [0.6793 0.6876 0.68   0.6717 0.6779 0.6728 0.6746 0.7017 0.6829 0.688 ]\n",
      "▶ 평균 Accuracy: 0.9615\n",
      "▶ 평균 Recall:   0.6817\n",
      "\n",
      "📊 [학생] Accuracy (10회): [0.8505 0.8454 0.8511 0.846  0.8439 0.8447 0.8506 0.8462 0.846  0.8533]\n",
      "📊 [학생] Recall    (10회): [0.8918 0.8861 0.8916 0.8808 0.8818 0.8827 0.888  0.8857 0.8818 0.8941]\n",
      "▶ 평균 Accuracy: 0.8478\n",
      "▶ 평균 Recall:   0.8864\n",
      "\n",
      "📊 [전체] Accuracy (10회): [0.9387 0.9391 0.9398 0.9383 0.9374 0.9377 0.9394 0.9402 0.9386 0.9405]\n",
      "📊 [전체] Recall    (10회): [0.8151 0.8144 0.8152 0.8053 0.8082 0.8069 0.8109 0.8193 0.81   0.8197]\n",
      "▶ 평균 Accuracy: 0.9390\n",
      "▶ 평균 Recall:   0.8125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# 📌 평가 지표 저장 리스트 초기화\n",
    "work_acc_list, work_rec_list = [], []\n",
    "stu_acc_list, stu_rec_list = [], []\n",
    "all_acc_list, all_rec_list = [], []\n",
    "\n",
    "# 📌 공통 모델 하이퍼파라미터 (random_state는 루프 내에서 넣음)\n",
    "base_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'use_label_encoder': False,\n",
    "    'eval_metric': 'logloss',\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# 📌 학습/테스트 분할 함수 정의 (seed 사용)\n",
    "def get_train_test_dataset(df, seed):\n",
    "    y = df['Depression']\n",
    "    X = df.drop('Depression', axis=1)\n",
    "    return train_test_split(X, y, test_size=0.3, stratify=y, random_state=seed)\n",
    "\n",
    "# 📌 10회 반복 학습 및 평가\n",
    "for seed in range(10):\n",
    "    # 데이터 분할 (seed 적용)\n",
    "    work_X_train, work_X_test, work_y_train, work_y_test = get_train_test_dataset(work_train, seed)\n",
    "    stu_X_train, stu_X_test, stu_y_train, stu_y_test = get_train_test_dataset(stu_train, seed)\n",
    "\n",
    "    # 직장인 모델 (seed 적용)\n",
    "    work_model = XGBClassifier(**base_params, random_state=seed)\n",
    "    work_model.fit(work_X_train, work_y_train)\n",
    "    work_y_pred = work_model.predict(work_X_test)\n",
    "    work_acc_list.append(accuracy_score(work_y_test, work_y_pred))\n",
    "    work_rec_list.append(recall_score(work_y_test, work_y_pred))\n",
    "\n",
    "    # 학생 모델 (seed 적용)\n",
    "    stu_model = XGBClassifier(**base_params, random_state=seed)\n",
    "    stu_model.fit(stu_X_train, stu_y_train)\n",
    "    stu_y_pred = stu_model.predict(stu_X_test)\n",
    "    stu_acc_list.append(accuracy_score(stu_y_test, stu_y_pred))\n",
    "    stu_rec_list.append(recall_score(stu_y_test, stu_y_pred))\n",
    "\n",
    "    # 전체 데이터 통합 평가\n",
    "    y_true_all = np.concatenate([work_y_test, stu_y_test])\n",
    "    y_pred_all = np.concatenate([work_y_pred, stu_y_pred])\n",
    "    all_acc_list.append(accuracy_score(y_true_all, y_pred_all))\n",
    "    all_rec_list.append(recall_score(y_true_all, y_pred_all))\n",
    "\n",
    "# 📌 결과 출력 함수\n",
    "def print_results(title, acc_list, rec_list):\n",
    "    print(f\"📊 [{title}] Accuracy (10회):\", np.round(acc_list, 4))\n",
    "    print(f\"📊 [{title}] Recall    (10회):\", np.round(rec_list, 4))\n",
    "    print(f\"▶ 평균 Accuracy: {np.mean(acc_list):.4f}\")\n",
    "    print(f\"▶ 평균 Recall:   {np.mean(rec_list):.4f}\")\n",
    "    print()\n",
    "\n",
    "# 📌 결과 출력\n",
    "print_results(\"직장인\", work_acc_list, work_rec_list)\n",
    "print_results(\"학생\", stu_acc_list, stu_rec_list)\n",
    "print_results(\"전체\", all_acc_list, all_rec_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9327326-b853-4c3a-8195-8047a82a5103",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. 결측치 임퓨팅 / 파생 변수 만든 후 모델링하면 성능 향상할 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f20d9ee0-9805-47b1-802f-ddc47609620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('~/Aiffel/DATAThon/playground-series-s4e11/train.csv')\n",
    "test = pd.read_csv('~/Aiffel/DATAThon/playground-series-s4e11/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6351cf51-a109-4b20-8067-68cbdef10355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요없는 컬럼 삭제\n",
    "train.drop(columns=['id'], inplace=True)\n",
    "train.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "# 결측치 처리\n",
    "train.drop(columns=['CGPA'], inplace=True)\n",
    "train['Academic_Pressure_missing'] = train['Academic Pressure'].isnull().astype(int)\n",
    "train['Study_Satisfaction_missing'] = train['Study Satisfaction'].isnull().astype(int)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "train['Academic Pressure'] = imputer.fit_transform(train[['Academic Pressure']])\n",
    "train['Study Satisfaction'] = imputer.fit_transform(train[['Study Satisfaction']])\n",
    "train['Work_Pressure_missing'] = train['Work Pressure'].isnull().astype(int)\n",
    "train['Job_Satisfaction_missing'] = train['Job Satisfaction'].isnull().astype(int)\n",
    "train['Work Pressure'] = imputer.fit_transform(train[['Work Pressure']])\n",
    "train['Job Satisfaction'] = imputer.fit_transform(train[['Job Satisfaction']])\n",
    "train = train[train['Financial Stress'].notnull()].copy()\n",
    "\n",
    "# 범주형 변수 처리\n",
    "delete_values = [\n",
    "    'Indore', 'Pune', 'Moderate', 'Unhealthy', 'Sleep_Duration',\n",
    "    'Work_Study_Hours', 'No', '45', '49 hours', '55-66 hours', '40-45 hours', \n",
    "    '9-5 hours', '10-6 hours', '9-6 hours', '9-5', '45-48 hours', '35-36 hours'\n",
    "]\n",
    "train = train[~train['Sleep Duration'].isin(delete_values)].copy()\n",
    "def convert_sleep_to_hours(val):\n",
    "    try:\n",
    "        val = str(val).strip().lower()\n",
    "        if 'than' in val and 'less' not in val and 'more' not in val:\n",
    "            match = re.search(r'\\d+', val)\n",
    "            if match:\n",
    "                return float(match.group()) - 0.5\n",
    "        if 'less than' in val:\n",
    "            match = re.search(r'\\d+', val)\n",
    "            if match:\n",
    "                return float(match.group()) - 0.5\n",
    "        elif 'more than' in val:\n",
    "            match = re.search(r'\\d+', val)\n",
    "            if match:\n",
    "                return float(match.group()) + 0.5\n",
    "        elif re.match(r'^\\d+\\s*hours$', val):\n",
    "            return float(re.findall(r'\\d+', val)[0])\n",
    "        elif re.search(r'\\d+\\s*[-–~]\\s*\\d+', val):\n",
    "            nums = [int(n) for n in re.findall(r'\\d+', val)]\n",
    "            if len(nums) == 2:\n",
    "                return sum(nums) / 2\n",
    "        elif re.match(r'^\\d+(\\.\\d+)?$', val):\n",
    "            return float(val)\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "train['Sleep Duration'] = train['Sleep Duration'].apply(convert_sleep_to_hours)\n",
    "degree_group_map = {\n",
    "    'MD': 'Medical',\n",
    "    'MBBS': 'Medical',\n",
    "    'B.Pharm': 'Pharmacy',\n",
    "    'M.Pharm': 'Pharmacy',\n",
    "    'MPharm': 'Pharmacy',\n",
    "    'P.Pharm': 'Pharmacy',\n",
    "    'S.Pharm': 'Pharmacy',\n",
    "    'N.Pharm': 'Pharmacy',\n",
    "    'B.Tech': 'Engineering',\n",
    "    'M.Tech': 'Engineering',\n",
    "    'ME': 'Engineering',\n",
    "    'MTech': 'Engineering',\n",
    "    'M_Tech': 'Engineering',\n",
    "    'BE': 'Engineering',\n",
    "    'BCA': 'Engineering',\n",
    "    'MCA': 'Engineering',\n",
    "    'E.Tech': 'Engineering',\n",
    "    'S.Tech': 'Engineering',\n",
    "    'LLTech': 'Engineering',\n",
    "    'LLCom': 'Engineering',\n",
    "    'BBA': 'Business',\n",
    "    'MBA': 'Business',\n",
    "    'M. Business Analyst': 'Business',\n",
    "    'B.Com': 'Commerce',\n",
    "    'M.Com': 'Commerce',\n",
    "    'P.Com': 'Commerce',\n",
    "    'LLB': 'Law',\n",
    "    'LLM': 'Law',\n",
    "    'LLBA': 'Law',\n",
    "    'LL.Com': 'Law',\n",
    "    'LL B.Ed': 'Education',\n",
    "    'B.Ed': 'Education',\n",
    "    'M.Ed': 'Education',\n",
    "    'L.Ed': 'Education',\n",
    "    'K.Ed': 'Education',\n",
    "    'LLEd': 'Education',\n",
    "    'BEd': 'Education',\n",
    "    'BSc': 'Science',\n",
    "    'MSc': 'Science',\n",
    "    'B.Sc': 'Science',\n",
    "    'BHM': 'Hospitality',\n",
    "    'MHM': 'Hospitality',\n",
    "    'B.Arch': 'Architecture',\n",
    "    'M.Arch': 'Architecture',\n",
    "    'BArch': 'Architecture',\n",
    "    'B.B.Arch': 'Architecture',\n",
    "    'PhD': 'PhD',\n",
    "    'Class 12': 'School',\n",
    "    'Class 11': 'School',\n",
    "}\n",
    "train['degree_group'] =train['Degree'].apply(lambda x: degree_group_map.get(x, 'Other'))\n",
    "train=train.drop('Degree',axis=1)\n",
    "\n",
    "top_cities = train['City'].value_counts().nlargest(15).index\n",
    "train['City'] = train['City'].where(train['City'].isin(top_cities), other='Other')\n",
    "\n",
    "valid_dietary = ['Moderate', 'Unhealthy', 'Healthy']\n",
    "train['Dietary Habits'] = train['Dietary Habits'].where(train['Dietary Habits'].isin(valid_dietary))\n",
    "train['Dietary Habits'] = train['Dietary Habits'].fillna(train['Dietary Habits'].mode()[0])\n",
    "\n",
    "binary_cols = ['Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
    "for col in binary_cols:\n",
    "    train[col] = train[col].map({'Yes': 1, 'No': 0})\n",
    "train['Gender'] = train['Gender'].map({'Male': 1, 'Female': 0})\n",
    "train['Working Professional or Student'] = train['Working Professional or Student'].map({'Working Professional': 1, 'Student': 0})\n",
    "\n",
    "# 수치형 변수 스케일링\n",
    "scale_cols = ['Sleep Duration', 'Work/Study Hours', 'Financial Stress']\n",
    "# scale_cols = ['Age', 'Sleep Duration', 'Work/Study Hours', 'Financial Stress']\n",
    "scaler = StandardScaler()\n",
    "train[scale_cols] = scaler.fit_transform(train[scale_cols])\n",
    "\n",
    "# 원핫인코딩 + 타겟인코딩\n",
    "train = pd.get_dummies(train, columns=['degree_group', 'Dietary Habits'], drop_first=True) # 다중공선성 방지를 위해 첫 번째 범주는 제거\n",
    "for col in ['Profession', 'City']:\n",
    "    target_mean = train.groupby(col)['Depression'].mean()\n",
    "    train[col + '_target'] = train[col].map(target_mean)\n",
    "    \n",
    "\n",
    "train.drop(columns=['Profession', 'City'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0badb1b3-099f-4837-a6e9-0949ab7bd002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "09eb5125-6071-411f-8ce7-b91d199cf786",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:45:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:45:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:45:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:45:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:45:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:45:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:45:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/choieunseo/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [20:45:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (10회): [0.938  0.9386 0.9383 0.9364 0.9391 0.9372 0.9384 0.9389 0.94   0.9377]\n",
      "Recall (10회):    [0.8061 0.8092 0.8114 0.8038 0.8074 0.8086 0.8065 0.8156 0.8191 0.8109]\n",
      "\n",
      "평균 Accuracy: 0.9383\n",
      "평균 Recall:   0.8099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "accuracy_list = []\n",
    "recall_list = []\n",
    "\n",
    "# 10회 반복\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        train.drop(columns=['Depression']),\n",
    "        train['Depression'],\n",
    "        test_size=0.3,\n",
    "        stratify=train['Depression'],\n",
    "        random_state=i  # 반복마다 seed 변경\n",
    "    )\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    recall_list.append(rec)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Accuracy (10회):\", np.round(accuracy_list, 4))\n",
    "print(\"Recall (10회):   \", np.round(recall_list, 4))\n",
    "print(f\"\\n평균 Accuracy: {np.mean(accuracy_list):.4f}\")\n",
    "print(f\"평균 Recall:   {np.mean(recall_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4989d1-aa50-4dff-a7c6-2e9b252c9617",
   "metadata": {},
   "source": [
    "## 4. ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc814e6-1f42-4392-b63b-34e04dadb332",
   "metadata": {},
   "source": [
    "| **가설**                           | **Accuracy (평균)** | **Recall (평균)** | **Accuracy (10회 측정값)**                                                            | **Recall (10회 측정값)**                                                              |\n",
    "| -------------------------------- | ----------------- | --------------- | --------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |\n",
    "| **가설 1**<br>(고유값 및 결측치 많은 컬럼 삭제) | 0.9130            | 0.6765          | \\[0.913, 0.9132, 0.9135, 0.9134, 0.9134, 0.9126, 0.914, 0.9118, 0.9131, 0.9118]   | \\[0.6815, 0.6733, 0.6793, 0.6747, 0.679, 0.6728, 0.6823, 0.6711, 0.6777, 0.6731]  |\n",
    "| **가설 2**<br>(학생/직장인 분리 모델링)      | 0.9390        | 0.8125     | \\[0.9387, 0.9391, 0.9398, 0.9383, 0.9374, 0.9377, 0.9394, 0.9402, 0.9386, 0.9405] | \\[0.8151, 0.8144, 0.8152, 0.8053, 0.8082, 0.8069, 0.8109, 0.8193, 0.81, 0.8197]   |\n",
    "| **가설 3**<br>(결측치 임퓨팅 + 파생변수 생성)  | 0.9383            | 0.8099          | \\[0.938, 0.9386, 0.9383, 0.9364, 0.9391, 0.9372, 0.9384, 0.9389, 0.94, 0.9377]    | \\[0.8061, 0.8092, 0.8114, 0.8038, 0.8074, 0.8086, 0.8065, 0.8156, 0.8191, 0.8109] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a3b120-e6ab-4676-9b39-6a33a049a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Accuracy 데이터\n",
    "acc_h1 = [0.913, 0.9132, 0.9135, 0.9134, 0.9134, 0.9126, 0.914, 0.9118, 0.9131, 0.9118]\n",
    "acc_h2 = [0.9387, 0.9391, 0.9398, 0.9383, 0.9374, 0.9377, 0.9394, 0.9402, 0.9386, 0.9405]\n",
    "acc_h3 = [0.938, 0.9386, 0.9383, 0.9364, 0.9391, 0.9372, 0.9384, 0.9389, 0.94, 0.9377]\n",
    "\n",
    "# Recall 데이터\n",
    "rec_h1 = [0.6815, 0.6733, 0.6793, 0.6747, 0.679, 0.6728, 0.6823, 0.6711, 0.6777, 0.6731]\n",
    "rec_h2 = [0.8151, 0.8144, 0.8152, 0.8053, 0.8082, 0.8069, 0.8109, 0.8193, 0.81, 0.8197]\n",
    "rec_h3 = [0.8061, 0.8092, 0.8114, 0.8038, 0.8074, 0.8086, 0.8065, 0.8156, 0.8191, 0.8109]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92701354-751c-4d30-8de0-b9a17f5c4472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene’s test for Accuracy:\n",
      "Statistic = 0.7865, p-value = 0.4656\n",
      "\n",
      "Levene’s test for Recall:\n",
      "Statistic = 0.3843, p-value = 0.6846\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "# Accuracy에 대한 등분산성 검정\n",
    "levene_acc = levene(acc_h1, acc_h2, acc_h3)\n",
    "print(\"Levene’s test for Accuracy:\")\n",
    "print(f\"Statistic = {levene_acc.statistic:.4f}, p-value = {levene_acc.pvalue:.4f}\")\n",
    "\n",
    "# Recall에 대한 등분산성 검정\n",
    "levene_rec = levene(rec_h1, rec_h2, rec_h3)\n",
    "print(\"\\nLevene’s test for Recall:\")\n",
    "print(f\"Statistic = {levene_rec.statistic:.4f}, p-value = {levene_rec.pvalue:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad76c64b-fd86-4c00-9867-ba5fbaf5e466",
   "metadata": {},
   "source": [
    "Levene’s(리빈스) 검정의 귀무가설(H₀):\n",
    "\n",
    "세 그룹의 분산이 서로 같다 (등분산이다)\n",
    "\n",
    "p-value가 0.05보다 크므로, 귀무가설을 기각할 수 없음\n",
    "\n",
    "즉, 세 집단의 분산이 통계적으로 유의미하게 다르지 않다 → 등분산성이 있다는 해석이 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d74b397b-406f-4540-a125-1c5d36848051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=np.float64(0.8991025445855032), pvalue=np.float64(0.21417490269488815))\n",
      "ShapiroResult(statistic=np.float64(0.9726550536536342), pvalue=np.float64(0.9143110414963821))\n",
      "ShapiroResult(statistic=np.float64(0.990107053988515), pvalue=np.float64(0.9969422624001061))\n",
      "ShapiroResult(statistic=np.float64(0.9207633142090637), pvalue=np.float64(0.36336527152231446))\n",
      "ShapiroResult(statistic=np.float64(0.9431801584219465), pvalue=np.float64(0.5889112848621444))\n",
      "ShapiroResult(statistic=np.float64(0.9361914536774865), pvalue=np.float64(0.5114632857063324))\n"
     ]
    }
   ],
   "source": [
    "print(stats.shapiro(acc_h1))\n",
    "print(stats.shapiro(acc_h2))\n",
    "print(stats.shapiro(acc_h3))\n",
    "\n",
    "print(stats.shapiro(rec_h1))\n",
    "print(stats.shapiro(rec_h2))\n",
    "print(stats.shapiro(rec_h3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733e980-ad6f-4674-a0d9-8b65f399e35f",
   "metadata": {},
   "source": [
    "🔍 Shapiro-Wilk 정규성 검정 요약\n",
    "Shapiro-Wilk 검정은 주어진 데이터가 정규 분포를 따르는지를 확인하는 검정입니다.\n",
    "\n",
    "귀무가설(H₀): 데이터는 정규분포를 따른다.\n",
    "\n",
    "대립가설(H₁): 데이터는 정규분포를 따르지 않는다.\n",
    "\n",
    "p-value > 0.05 → 정규성 만족 (H₀ 채택)\n",
    "\n",
    "p-value ≤ 0.05 → 정규성 위반 (H₀ 기각)\n",
    "\n",
    "| 통계량 (`statistic`) | p-value | 정규성 만족 여부       |\n",
    "| ----------------- | ------- | --------------- |\n",
    "| 0.8991            | 0.2142  | ✅ 만족 (p > 0.05) |\n",
    "| 0.9727            | 0.9143  | ✅ 만족            |\n",
    "| 0.9901            | 0.9969  | ✅ 만족            |\n",
    "| 0.9208            | 0.3634  | ✅ 만족            |\n",
    "| 0.9432            | 0.5889  | ✅ 만족            |\n",
    "| 0.9362            | 0.5115  | ✅ 만족            |\n",
    "\n",
    "모든 데이터셋에서 p-value가 모두 0.05보다 큽니다.\n",
    "따라서 모든 케이스에서 정규성 가정을 만족한다고 볼 수 있습니다.\n",
    "\n",
    "이 결과는 ANOVA나 Tukey HSD처럼 정규성 가정을 전제로 하는 통계검정을 수행하는 데에 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "055ce74b-46c6-499e-9b93-f299731a1ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Accuracy] F = 2531.0216, p = 0.0000\n",
      "[Recall]   F = 2915.2928, p = 0.0000\n"
     ]
    }
   ],
   "source": [
    "f_acc, p_acc = stats.f_oneway(acc_h1, acc_h2, acc_h3)\n",
    "\n",
    "# 🎯 Recall에 대한 분산분석\n",
    "f_rec, p_rec = stats.f_oneway(rec_h1, rec_h2, rec_h3)\n",
    "\n",
    "print(f\"[Accuracy] F = {f_acc:.4f}, p = {p_acc:.4f}\")\n",
    "print(f\"[Recall]   F = {f_rec:.4f}, p = {p_rec:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77035732-44b1-46d7-89d6-9b7694b861fb",
   "metadata": {},
   "source": [
    "✅ 1. 정규성 만족\n",
    "앞서 Shapiro-Wilk 검정 결과에서 모든 그룹의 정규성 만족 → OK\n",
    "✔️ ANOVA 수행 가능 조건 충족\n",
    "\n",
    "✅ 2. 분산분석 (ANOVA) 결과\n",
    "```\n",
    "[Accuracy] F = 2531.0216, p = 0.0000\n",
    "[Recall]   F = 2915.2928, p = 0.0000\n",
    "```\n",
    "🔍 해석:\n",
    "귀무가설(H₀): 세 그룹의 평균은 모두 같다\n",
    "\n",
    "대립가설(H₁): 적어도 하나의 그룹은 평균이 다르다\n",
    "\n",
    "✅ p-value ≪ 0.05 → 귀무가설 기각\n",
    "👉 즉, 세 그룹 중 적어도 하나는 평균이 유의하게 다르다!\n",
    "따라서:\n",
    "\n",
    "✅ 3. 사후검정 (Tukey HSD) 수행 필요\n",
    "분산분석은 “차이가 있다”는 것까지만 알려줍니다.\n",
    "어느 그룹 간에 차이가 있는지는 알려주지 않기 때문에,\n",
    "→ 바로 이어서 Tukey HSD 사후검정을 해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fc7984e2-ef59-4958-b5f7-e94186359941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Multiple Comparison of Means - Tukey HSD, FWER=0.05      \n",
      "===============================================================\n",
      "   group1       group2    meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------------------\n",
      "hypothesis_1 hypothesis_2    0.026    0.0   0.025  0.027   True\n",
      "hypothesis_1 hypothesis_3   0.0253    0.0  0.0242 0.0263   True\n",
      "hypothesis_2 hypothesis_3  -0.0007 0.2213 -0.0017 0.0003  False\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Accuracy 예시\n",
    "acc_1 = [0.913, 0.9132, 0.9135, 0.9134, 0.9134, 0.9126, 0.914, 0.9118, 0.9131, 0.9118]\n",
    "acc_2 = [0.9387, 0.9391, 0.9398, 0.9383, 0.9374, 0.9377, 0.9394, 0.9402, 0.9386, 0.9405]\n",
    "acc_3 = [0.938, 0.9386, 0.9383, 0.9364, 0.9391, 0.9372, 0.9384, 0.9389, 0.94, 0.9377]\n",
    "\n",
    "# 그룹 이름 지정\n",
    "acc = acc_1 + acc_2 + acc_3\n",
    "group = ['hypothesis_1']*10 + ['hypothesis_2']*10 + ['hypothesis_3']*10\n",
    "\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame({'accuracy': acc, 'group': group})\n",
    "\n",
    "# Tukey’s HSD test 수행\n",
    "tukey_result = pairwise_tukeyhsd(endog=df['accuracy'], groups=df['group'], alpha=0.05)\n",
    "print(tukey_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df7d81c-0d9b-461e-bac3-917b87cbc508",
   "metadata": {},
   "source": [
    "| 그룹명           | 평균 AUC  |\n",
    "| ------------- | ------- |\n",
    "| hypothesis\\_1 | 약 0.913 |\n",
    "| hypothesis\\_2 | 약 0.939 |\n",
    "| hypothesis\\_3 | 약 0.938 |\n",
    "\n",
    "hypothesis_1은 다른 두 그룹보다 AUC가 유의하게 낮음\n",
    "\n",
    "hypothesis_2와 hypothesis_3 간에는 차이 없음 → 성능 유사\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bd8eb541-7855-4500-96cc-d6cd4ff7f697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Multiple Comparison of Means - Tukey HSD, FWER=0.05      \n",
      "===============================================================\n",
      "   group1       group2    meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------------------\n",
      "hypothesis_1 hypothesis_2    0.136    0.0   0.131 0.1411   True\n",
      "hypothesis_1 hypothesis_3   0.1334    0.0  0.1283 0.1384   True\n",
      "hypothesis_2 hypothesis_3  -0.0026 0.4097 -0.0077 0.0024  False\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Recall 값 예시\n",
    "rec_1 = [0.6815, 0.6733, 0.6793, 0.6747, 0.6790, 0.6728, 0.6823, 0.6711, 0.6777, 0.6731]\n",
    "rec_2 = [0.8151, 0.8144, 0.8152, 0.8053, 0.8082, 0.8069, 0.8109, 0.8193, 0.81, 0.8197]\n",
    "rec_3 = [0.8061, 0.8092, 0.8114, 0.8038, 0.8074, 0.8086, 0.8065, 0.8156, 0.8191, 0.8109]\n",
    "\n",
    "# 그룹 이름 지정\n",
    "recall = rec_1 + rec_2 + rec_3\n",
    "group = ['hypothesis_1'] * 10 + ['hypothesis_2'] * 10 + ['hypothesis_3'] * 10\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame({'recall': recall, 'group': group})\n",
    "\n",
    "# Tukey’s HSD test 수행\n",
    "tukey_result = pairwise_tukeyhsd(endog=df['recall'], groups=df['group'], alpha=0.05)\n",
    "\n",
    "print(tukey_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a994a62-ba3f-4eb7-af28-a68e7f6ca998",
   "metadata": {},
   "source": [
    "🔍 ✅ 비교: hypothesis_2 vs hypothesis_3\n",
    "\n",
    "📌 귀무가설 (Null Hypothesis, H₀)\n",
    "두 그룹의 평균은 같다\n",
    "→ 𝜇₂ = 𝜇₃\n",
    "→ recall의 평균 차이 = 0\n",
    "\n",
    "📌 대립가설 (Alternative Hypothesis, H₁)\n",
    "두 그룹의 평균은 다르다\n",
    "→ 𝜇₂ ≠ 𝜇₃\n",
    "→ recall의 평균 차이 ≠ 0\n",
    "\n",
    "🔬 해석 결과\n",
    "p-value = 0.4097 > 0.05 → 귀무가설 기각하지 못함\n",
    "\n",
    "즉, 통계적으로 평균에 차이가 있다고 보기 어렵다\n",
    "\n",
    "✅ 결론 정리\n",
    "가설(H₀): “hypothesis_2와 hypothesis_3는 같은 평균 recall을 가진다.”\n",
    "결과: “데이터 상에서는 차이가 나지만, 이 차이가 우연에 의한 것일 수도 있다”\n",
    "→ 따라서 H₀를 유지함 → \"차이 없음\"으로 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961bf146-42b5-44c5-bb49-0a9e3dac5702",
   "metadata": {},
   "source": [
    "❌ hypothesis_2 vs hypothesis_3\n",
    "평균 차이: -0.0026\n",
    "\n",
    "p-value: 0.4097\n",
    "\n",
    "신뢰구간: (-0.0077, 0.0024)\n",
    "\n",
    "reject = False → 차이 없음\n",
    "\n",
    "👉 결론: hypothesis_2와 hypothesis_3 간 recall 차이는 통계적으로 유의하지 않음\n",
    "\n",
    "hypothesis_2와 hypothesis_3 간에는 유의미한 차이 없음 → 성능은 유사함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d999540a-f7d7-4197-bda6-012c5f488af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Multiple Comparison of Means - Tukey HSD, FWER=0.05      \n",
      "===============================================================\n",
      "   group1       group2    meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------------------\n",
      "hypothesis_1 hypothesis_2    0.136    0.0   0.131 0.1411   True\n",
      "hypothesis_1 hypothesis_3   0.1334    0.0  0.1283 0.1384   True\n",
      "hypothesis_2 hypothesis_3  -0.0026 0.4097 -0.0077 0.0024  False\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Recall 데이터\n",
    "recall_1 = [0.6815, 0.6733, 0.6793, 0.6747, 0.679, 0.6728, 0.6823, 0.6711, 0.6777, 0.6731]  # 낮음\n",
    "recall_2 = [0.8151, 0.8144, 0.8152, 0.8053, 0.8082, 0.8069, 0.8109, 0.8193, 0.81, 0.8197]  # 높음\n",
    "recall_3 = [0.8061, 0.8092, 0.8114, 0.8038, 0.8074, 0.8086, 0.8065, 0.8156, 0.8191, 0.8109]  # 중간\n",
    "\n",
    "# 평균 높은 순으로 group 라벨 매핑\n",
    "recall = recall_1 + recall_2 + recall_3\n",
    "group = ['hypothesis_1']*10 + ['hypothesis_2']*10 + ['hypothesis_3']*10\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame({'recall': recall, 'group': group})\n",
    "\n",
    "# Tukey HSD 수행\n",
    "tukey_result = pairwise_tukeyhsd(endog=df['recall'], groups=df['group'], alpha=0.05)\n",
    "print(tukey_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb5517-b429-4cc6-b70a-517c6e446d08",
   "metadata": {},
   "source": [
    "hypothesis_2 vs hypothesis_3 간 차이는 작고 통계적으로 유의하지 않다\n",
    "\n",
    "평균 차이 = -0.0026 (매우 작음)\n",
    "\n",
    "신뢰구간: 0을 포함함\n",
    "\n",
    "p-value = 0.4097 → 귀무가설 기각할 수 없음 → 두 모델의 성능은 동일하다고 봄\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08733f-b1a4-4de1-9407-5dac327d73bb",
   "metadata": {},
   "source": [
    "모델 간 평균 성능 차이를 통계적으로 검증하기 위해 ANOVA 분석을 수행한 뒤,\n",
    "\n",
    "개별 모델 쌍 간의 유의미한 차이 여부를 평가하기 위해 Tukey HSD 사후검정을 추가로 시행하였다.\n",
    "\n",
    "특히, 가설 2와 가설 3은 평균 성능이 근접한 것으로 나타나,\n",
    "\n",
    "두 모델의 실제 성능이 유사한지를 통계적으로 확인하는 데 이 사후검정이 사용되었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
